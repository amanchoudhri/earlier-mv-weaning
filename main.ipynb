{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the Effect of Earlier Weaning off Mechanical Ventilation\n",
    "This project aims to use causal inference to estimate the effects of weaning patients off mechanical ventilation sooner than normal, following the approach described in [Kennedy, 2018](https://arxiv.org/pdf/1704.00211.pdf). In our dataset we consider patients who have been on mechanical ventilation for 24 hours (our start criteria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# ALL_WEANING_PREDICTORS is a list of all covariates intially identified as potentially useful in predicting probability of weaning\n",
    "# group_by_stay is a helper function that groups a dataframe by the column 'stay_id'\n",
    "from common import (\n",
    "    ALL_WEANING_PREDICTORS,\n",
    "    group_by_stay,\n",
    "    remove_outliers,\n",
    "    remove_extremes,\n",
    ")\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we exclude variables from consideration if they are missing more than 10% of the time in post-baseline times. Post-baseline in this case means we filter out records from patients at time points before our start criteria.\n",
    "\n",
    "```\n",
    ">>> full_df = pd.read_csv('full_weaning_dataset.csv')\n",
    ">>> post_baseline_df = full_df.loc[full_df['hour_baseline'] >= 0]\n",
    "```\n",
    "We sample a subset of patiets from this post-baseline dataframe and use that as our dataset for this notebook.\n",
    "```\n",
    ">>> stay_ids = post_baseline_df['stay_id'].unique()\n",
    ">>> print(len(stay_ids))\n",
    "8055\n",
    "```\n",
    "Get a random sample of about 5% of the stay_ids.\n",
    "```\n",
    ">>> stays = np.random.choice(stay_ids, size=500)\n",
    ">>> post_baseline_df.loc[post_baseline_df['stay_id'].isin(stays)].to_csv('sampled_post_baseline.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the sampled dataset\n",
    "df = pd.read_csv('sampled_post_baseline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before testing which variables are missing, we fill missing urine output (`urine_output`) and vasopressor (`rate_std`) values with 0, since missing entries for these two columns means the value is 0 in this dataset. We do this to make sure we don't exclude the columns from the dataset when we shouldn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['urine_output', 'rate_std']] = df[['urine_output', 'rate_std']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we forward fill all columns except for `amount` on a per-patient basis. Their values may only be measured occasionally, which is fine since the previous measurement of these values is important, not whether they were measured recently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for c in ALL_WEANING_PREDICTORS:\n",
    "    if c == 'amount': continue\n",
    "    df.loc[:, c] = group_by_stay(df, c).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fio2: 0.25\n",
      "carboxyhemoglobin: 0.931\n",
      "methemoglobin: 0.945\n",
      "ALBUMIN: 0.24\n",
      "BANDS: 0.655\n",
      "BILIRUBIN: 0.147\n",
      "marital_status: 0.119\n"
     ]
    }
   ],
   "source": [
    "LEN_DF = len(df)\n",
    "cols_to_exclude = set()\n",
    "for c in ALL_WEANING_PREDICTORS:\n",
    "    na_proportion = df[c].isna().sum() / LEN_DF\n",
    "    if na_proportion >= 0.1:\n",
    "        cols_to_exclude.add(c)\n",
    "        print(f\"{c}: {round(na_proportion, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've identified which columns should be excluded from our analysis, we can create a new list of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaning_predictors = [c for c in ALL_WEANING_PREDICTORS if c not in cols_to_exclude]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to process the data and remove outliers. The `remove_outliers` function essentially writes over implausible values with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'amount'] = df['amount']/1000\n",
    "df.loc[:, 'last_amount'] = df['last_amount']/1000\n",
    "\n",
    "remove_outliers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can standardize our predictors and create a model for the probability of weaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tidal_volume_set</th>\n",
       "      <th>tidal_volume_observed</th>\n",
       "      <th>plateau_pressure</th>\n",
       "      <th>ventilator_type</th>\n",
       "      <th>peep_set</th>\n",
       "      <th>tidal_volume_set</th>\n",
       "      <th>tidal_volume_observed</th>\n",
       "      <th>plateau_pressure</th>\n",
       "      <th>ventilator_type</th>\n",
       "      <th>peep_set</th>\n",
       "      <th>...</th>\n",
       "      <th>last_CREATININE</th>\n",
       "      <th>last_PLATELET</th>\n",
       "      <th>last_PTT</th>\n",
       "      <th>last_INR</th>\n",
       "      <th>last_PT</th>\n",
       "      <th>last_BUN</th>\n",
       "      <th>last_WBC</th>\n",
       "      <th>last_urine_output</th>\n",
       "      <th>last_GLUCOSE</th>\n",
       "      <th>last_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.654549e-16</td>\n",
       "      <td>-4.275184e-16</td>\n",
       "      <td>1.382913e-16</td>\n",
       "      <td>-6.298554e-17</td>\n",
       "      <td>1.073852e-16</td>\n",
       "      <td>1.654549e-16</td>\n",
       "      <td>-4.275184e-16</td>\n",
       "      <td>1.382913e-16</td>\n",
       "      <td>-6.298554e-17</td>\n",
       "      <td>1.073852e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.912502e-16</td>\n",
       "      <td>-2.390694e-17</td>\n",
       "      <td>3.776379e-16</td>\n",
       "      <td>6.553161e-16</td>\n",
       "      <td>2.016357e-16</td>\n",
       "      <td>-2.702597e-17</td>\n",
       "      <td>2.261550e-16</td>\n",
       "      <td>-1.631025e-17</td>\n",
       "      <td>1.101768e-16</td>\n",
       "      <td>-1.610924e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tidal_volume_set  tidal_volume_observed  plateau_pressure  \\\n",
       "mean      1.654549e-16          -4.275184e-16      1.382913e-16   \n",
       "std       1.000005e+00           1.000005e+00      1.000005e+00   \n",
       "\n",
       "      ventilator_type      peep_set  tidal_volume_set  tidal_volume_observed  \\\n",
       "mean    -6.298554e-17  1.073852e-16      1.654549e-16          -4.275184e-16   \n",
       "std      1.000005e+00  1.000005e+00      1.000005e+00           1.000005e+00   \n",
       "\n",
       "      plateau_pressure  ventilator_type      peep_set  ...  last_CREATININE  \\\n",
       "mean      1.382913e-16    -6.298554e-17  1.073852e-16  ...    -1.912502e-16   \n",
       "std       1.000005e+00     1.000005e+00  1.000005e+00  ...     1.000005e+00   \n",
       "\n",
       "      last_PLATELET      last_PTT      last_INR       last_PT      last_BUN  \\\n",
       "mean  -2.390694e-17  3.776379e-16  6.553161e-16  2.016357e-16 -2.702597e-17   \n",
       "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
       "\n",
       "          last_WBC  last_urine_output  last_GLUCOSE   last_weight  \n",
       "mean  2.261550e-16      -1.631025e-17  1.101768e-16 -1.610924e-16  \n",
       "std   1.000005e+00       1.000008e+00  1.000005e+00  1.000005e+00  \n",
       "\n",
       "[2 rows x 120 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If a column for the measurement of a given value at time t-1 exists, add it to the predictors\n",
    "for c in weaning_predictors:\n",
    "    try:\n",
    "        df['last_' + c]\n",
    "        weaning_predictors.append('last_' + c)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "# Standardize predictors\n",
    "numeric = df[weaning_predictors].select_dtypes(exclude='object').columns\n",
    "df.loc[:, numeric] = StandardScaler().fit_transform(df[numeric])\n",
    "# Sanity check to make sure the DataFrame was actually standardized\n",
    "df[numeric].agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before modeling the probability of weaning, we'll impute medians and remove extreme values from the covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in numeric:\n",
    "    df.loc[:, c].fillna(df[c].median(), inplace=True)\n",
    "\n",
    "remove_extremes(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARAMS = {\n",
    "    'penalty': 'l2',\n",
    "    'max_iter': 1000,\n",
    "}\n",
    "def _model(rows, predictors, label, options=MODEL_PARAMS):\n",
    "    \"\"\"Given the desired rows, predictors of a category, and label of that category, return a fitted sklearn logistic regressor.\"\"\"\n",
    "    # Encode any necessary columns that aren't encoded as integers\n",
    "    data = df.loc[rows, predictors + [label]]\n",
    "    for col in data.select_dtypes(include='object'):\n",
    "        data.loc[:, col] = LabelEncoder().fit_transform(data[col])\n",
    "    return LogisticRegression(**options).fit(data[predictors], data[label])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56b99ba35fbf06c4dc463b67e081262ac24be503d9ee1adee8d3ec32db9e0e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "974242ba8bd4aee876d4cc6b2b4fd6d90080efacd3e889d4fd5fe2f92b3a2fbb"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}